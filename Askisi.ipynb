{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3fb988-27d1-4cdf-ab8d-aa7a5f7d5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb523cb-70c2-4bbd-b78d-60c61222b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tpoul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tpoul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tpoul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c430c-274a-491b-81b2-88b3bab4ffff",
   "metadata": {},
   "source": [
    "# Information Retrieval System\n",
    "### Περιγραφή\n",
    "Το παρόν Notebook περιέχει την υλοποίηση και αξιολόγηση μιας μηχανής αναζήτησης σύμφωνα με τις οδηγίες του έργου."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a851bc-55a1-44d3-94e7-b08ad009c62d",
   "metadata": {},
   "source": [
    "## Συλλογή Δεδομένων\n",
    "Αυτή η ενότητα συλλέγει άρθρα από το Wikipedia χρησιμοποιώντας το API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f71e82-d241-47d6-a0fa-3442d5b52e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikipedia_articles(query, article_count):\n",
    "    \"\"\"\n",
    "    Fetches articles from Wikipedia using a search query and a specified number of results.\n",
    "    \"\"\"\n",
    "    base_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    articles = []\n",
    "\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'list': 'search',\n",
    "        'srsearch': query,\n",
    "        'srlimit': article_count\n",
    "    }\n",
    "\n",
    "    # Web Crawler\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get('query', {}).get('search', [])\n",
    "        for result in results:\n",
    "            title = result['title']\n",
    "            content = fetch_article_content(title)\n",
    "            if content:\n",
    "                articles.append({\n",
    "                    'title': title,\n",
    "                    'content': preprocess_text(content)\n",
    "                })\n",
    "\n",
    "    # Save results as JSON\n",
    "    with open(f'{query}_wikipedia_data.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(articles, file, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return articles, create_inverted_index(articles)\n",
    "\n",
    "def fetch_article_content(title):\n",
    "    \"\"\"\n",
    "    Fetches the full content of a Wikipedia article given its title.\n",
    "    \"\"\"\n",
    "    base_url = f\"https://en.wikipedia.org/wiki/{title.replace(' ', '_')}\"\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        content = \" \".join(p.text for p in paragraphs if p.text.strip())\n",
    "        return content\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de567168-5598-405d-bad9-8ea49d5841c8",
   "metadata": {},
   "source": [
    "## Προεπεξεργασία Κειμένου\n",
    "Επεξεργασία του κειμένου: τοκενικοποίηση, αφαίρεση stop-words, λημματοποίηση και stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c237ae0-567c-4e6d-9ba6-37dbd37510b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(raw_text):\n",
    "    \"\"\"\n",
    "    Processes raw text: tokenization, stop-word removal, lemmatization, and stemming.\n",
    "    \"\"\"\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(raw_text)\n",
    "\n",
    "    # Stop-word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [t for t in tokens if t.isalnum() and t.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
    "\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd663139-2c36-49ec-9829-73b64b2eb089",
   "metadata": {},
   "source": [
    "## Δημιουργία Ευρετηρίου\n",
    "Κατασκευή ανεστραμμένου ευρετηρίου για αποδοτική ανάκτηση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e5bd7c-c603-4035-b5e0-793dd8ebe0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index(documents):\n",
    "    \"\"\"\n",
    "    Builds an inverted index for efficient retrieval.\n",
    "    \"\"\"\n",
    "    index = defaultdict(set)\n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        for word in doc.get('content', []):\n",
    "            index[word].add(doc_id)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04204cbb-9fba-4826-9f63-df693a41a3be",
   "metadata": {},
   "source": [
    "## Μηχανή Αναζήτησης\n",
    "Παρέχει τη δυνατότητα αναζήτησης με Boolean, VSM ή BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332a463a-9519-4fd8-9381-43125e281427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_search():\n",
    "    \"\"\"\n",
    "    Prompts user to perform dynamic searches.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        query = input(\"Enter your search query (or type 'exit' to quit): \").strip()\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Exiting search engine. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        article_count = int(input(\"Enter number of articles to fetch: \").strip())\n",
    "        documents, index = fetch_wikipedia_articles(query=query, article_count=article_count)\n",
    "\n",
    "        retrieval_method = input(\"Choose retrieval model (BOOLEAN, VSM, BM25): \").upper()\n",
    "        if retrieval_method not in ['BOOLEAN', 'VSM', 'BM25']:\n",
    "            print(\"Invalid choice. Please select BOOLEAN, VSM, or BM25.\")\n",
    "            continue\n",
    "\n",
    "        results = retrieve_documents(query, retrieval_method, documents, index)\n",
    "        if results:\n",
    "            display_search_results(results)\n",
    "\n",
    "            # Evaluation Section\n",
    "            print(\"\\nEvaluating system performance...\")\n",
    "            evaluate_system(documents, results, query)\n",
    "        else:\n",
    "            print(\"No relevant documents found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89053d22-21c1-41ac-afa5-e8b4da237f6d",
   "metadata": {},
   "source": [
    "## Αλγόριθμοι Ανάκτησης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "919f99c4-7ab7-45b5-b535-42b1e83941c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query, method, documents, index):\n",
    "    \"\"\"\n",
    "    Handles retrieval based on the selected method.\n",
    "    \"\"\"\n",
    "    if method == 'BOOLEAN':\n",
    "        return boolean_model(query, index, documents)\n",
    "    elif method == 'VSM':\n",
    "        return vector_space_model(query, documents)\n",
    "    elif method == 'BM25':\n",
    "        return bm25_model(query, documents)\n",
    "\n",
    "def boolean_model(query, index, docs):\n",
    "    \"\"\"\n",
    "    Implements Boolean retrieval model.\n",
    "    \"\"\"\n",
    "    terms = query.split()\n",
    "    matching_docs = set(range(len(docs)))\n",
    "    for term in terms:\n",
    "        if term in index:\n",
    "            matching_docs &= index[term]\n",
    "    return [docs[i] for i in matching_docs]\n",
    "\n",
    "def vector_space_model(query, docs):\n",
    "    \"\"\"\n",
    "    Implements Vector Space Model retrieval.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    contents = [\" \".join(doc['content']) for doc in docs]\n",
    "    tfidf_matrix = vectorizer.fit_transform([query] + contents)\n",
    "    scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "    ranked_indices = np.argsort(scores)[::-1]\n",
    "    return [docs[i] for i in ranked_indices if scores[i] > 0]\n",
    "\n",
    "def bm25_model(query, docs, k1=1.5, b=0.75):\n",
    "    \"\"\"\n",
    "    Implements a simplified BM25 model.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    contents = [\" \".join(doc['content']) for doc in docs]\n",
    "    tfidf_matrix = vectorizer.fit_transform([query] + contents)\n",
    "    doc_lengths = np.array([len(c.split()) for c in contents])\n",
    "    avg_length = np.mean(doc_lengths)\n",
    "\n",
    "    scores = []\n",
    "    for idx, content in enumerate(contents):\n",
    "        score = 0\n",
    "        for term in query.split():\n",
    "            term_freq = content.split().count(term)\n",
    "            idf = vectorizer.idf_[vectorizer.vocabulary_.get(term, 0)]\n",
    "            score += idf * ((term_freq * (k1 + 1)) / (term_freq + k1 * (1 - b + b * (doc_lengths[idx] / avg_length))))\n",
    "        scores.append((idx, score))\n",
    "\n",
    "    ranked_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    return [docs[i] for i, _ in ranked_scores if _ > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1086aa-8b27-4ae6-a12b-b963d80a44bb",
   "metadata": {},
   "source": [
    "## Εμφάνιση Αποτελεσμάτων\n",
    "Παρουσίαση των αποτελεσμάτων σε φιλική προς το χρήστη μορφή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1ce5dad-0e52-47e4-b53d-d482a09d90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(results):\n",
    "    \"\"\"\n",
    "    Outputs search results in a user-friendly format.\n",
    "    \"\"\"\n",
    "    for idx, result in enumerate(results, 1):\n",
    "        print(f\"{idx}. Title: {result['title']}\")\n",
    "        print(f\"Preview: {' '.join(result['content'][:30])}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0cd228-c81c-40d2-a5ec-7b8cfcec7380",
   "metadata": {},
   "source": [
    "## Μετρικές Αξιολόγησης\n",
    "Υπολογισμός Precision, Recall, F1-Score και MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee37a33-510e-44cc-825e-090f2ff8f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query (or type 'exit' to quit):  sun\n",
      "Enter number of articles to fetch:  10\n",
      "Choose retrieval model (BOOLEAN, VSM, BM25):  boolean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: Sun\n",
      "Preview: sun star center solar system massiv nearli perfect sphere hot plasma heat incandesc nuclear fusion reaction core radiat energi surfac mainli visibl light infrar radiat 10 ultraviolet energi far import...\n",
      "\n",
      "2. Title: Sun (disambiguation)\n",
      "Preview: sun star center solar system sun may also refer...\n",
      "\n",
      "3. Title: Sun sun\n",
      "Preview: sun sun may refer...\n",
      "\n",
      "4. Title: Sun, Sun, Sun\n",
      "Preview: sun sun sun second album indi band elect releas 2006 sub pop 7 2000 indi rock articl stub help wikipedia expand...\n",
      "\n",
      "5. Title: Sun Sun\n",
      "Preview: sun sun 15th album casiopea record releas 1986 casiopea addit musician 1980 jazz articl stub help wikipedia expand...\n",
      "\n",
      "6. Title: Sun Red Sun\n",
      "Preview: sun red sun american heavi metal project creat guitarist al romano also featur sever promin musician vocalist ray gillen badland black sabbath john west artens royal hunt drummer bobbi rondinelli...\n",
      "\n",
      "7. Title: Sun Sun Thatha\n",
      "Preview: sun sun thatha transl grandfath sun sun 2012 tamil languag independ drama film direct nassar film star support role son abi hassan jamali shadat lead role hiatu nassar return direct...\n",
      "\n",
      "8. Title: Sun Zhiwei\n",
      "Preview: sun zhiwei chines 孙智伟 pinyin sūn zhìwěi sun born octob 16 1965 chines mathematician work primarili number theori combinator group theori professor nanj univers sun zhiwei born jiangsu sun twin...\n",
      "\n",
      "9. Title: The Baltimore Sun\n",
      "Preview: baltimor sun largest daili newspap base state maryland provid coverag local region nation intern news 3 found 1837 newspap own tribun publish may 2021 acquir alden global capit oper medium...\n",
      "\n",
      "10. Title: The Sun (United Kingdom)\n",
      "Preview: defunct sun british tabloid newspap publish new group newspap divis new uk wholli own subsidiari lachlan murdoch new 9 10 found broadsheet 1964 successor daili herald becam tabloid 1969 purchas...\n",
      "\n",
      "\n",
      "Evaluating system performance...\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-Score: 0.67\n",
      "MAP: 1.00\n"
     ]
    }
   ],
   "source": [
    "def evaluate_system(documents, results, query):\n",
    "    \"\"\"\n",
    "    Evaluate system using Precision, Recall, F1-Score, and MAP.\n",
    "    \"\"\"\n",
    "    # Ground truth: Assume first half of documents are relevant (for demo purposes)\n",
    "    true_relevance = [1 if i < len(documents) // 2 else 0 for i in range(len(documents))]\n",
    "    retrieved_relevance = [1 if doc in results else 0 for doc in documents]\n",
    "\n",
    "    precision = precision_score(true_relevance, retrieved_relevance)\n",
    "    recall = recall_score(true_relevance, retrieved_relevance)\n",
    "    f1 = f1_score(true_relevance, retrieved_relevance)\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "    def mean_average_precision(true_relevance, retrieved_relevance):\n",
    "        relevant = 0\n",
    "        avg_precision = 0\n",
    "        for i, val in enumerate(retrieved_relevance):\n",
    "            if val == 1 and true_relevance[i] == 1:\n",
    "                relevant += 1\n",
    "                avg_precision += relevant / (i + 1)\n",
    "        return avg_precision / sum(true_relevance)\n",
    "\n",
    "    map_score = mean_average_precision(true_relevance, retrieved_relevance)\n",
    "    print(f\"MAP: {map_score:.2f}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    execute_search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
